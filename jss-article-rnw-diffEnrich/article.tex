\documentclass[article]{jss}\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

%% -- LaTeX packages and custom commands ---------------------------------------

%% recommended packages
\usepackage{thumbpdf,lmodern}
\usepackage{textcomp}

%% another package (only for this demo article)
\usepackage{framed}

%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}

%% For Sweave-based articles about R packages:
%% need no \usepackage{Sweave}
%% \SweaveOpts{engine=R, eps=FALSE, keep.source = TRUE}



%% -- Article metainformation (author, title, ...) -----------------------------

%% - \author{} with primary affiliation
%% - Separate authors by \And or \AND (in \author).
%% - \AND starts a new line, \And does not.
\author{Harry A. Smith\\Department of Biostatistics and Informatics
\\Colorado School of Public Health\\Skaggs School of Pharmacy\\and
Pharmaceutical Sciences
   \And Laura Saba\\Skaggs School of Pharmacy\\and
Pharmaceutical Sciences}
%% \Plainauthor{Achim Zeileis, Second Author}

%% - \title{} in title case
%% - \Plaintitle{} without LaTeX markup (if any)
%% - \Shorttitle{} with LaTeX markup (if any), used as running title
\title{diffEnrich: An \proglang{R} Package to Compare Functional Enrichment Between Two
Experimentally-derived Groups of Genes by Connecting to the KEGG REST API}
\Plaintitle{diffEnrich: An R Package to Compare Functional Enrichment Between Two
Experimentally-derived Groups of Genes by Connecting to the KEGG REST API}
\Shorttitle{The \proglang{R} Package diffEnrich}

%% - \Abstract{} almost as usual
\Abstract{
  \textbf{Motivation:} To aid in the biological interpretation of a list of candidate
  genes and proteins generated as part of omics studies, researchers quantitate
  the enrichment of known pathways or biological functions among the genes of
  interest. With the advent of new technologies and new experimental designs,
  it is often of interest to compare enrichment of a particular pathway between
  two gene lists (i.e., differential enrichment).
  \textbf{Results:} This package provides a number of functions that are intended to be
  used in a pipeline. Briefly, a function within the package will map
  species-specific ENTREZ gene IDs to their respective Kyoto Encyclopedia of
  Genes and Genomes (KEGG) pathways by accessing the KEGG REST API. The KEGG API
  is used to guarantee the most up-to-date pathway data from KEGG. Next, another
  function will identify significantly enriched pathways in two gene sets
  independently. The user can then identify pathways that are differentially
  enriched between the two gene sets using a third function. This package also
  provides a plotting function.
  \textbf{Availability and implementation:} diffEnrich is freely available on the
  Comprehensive R Archive Network (CRAN). Issues and bug reports can be submitted
  to the GitHub page \url{https://github.com/SabaLab/diffEnrich/issues}.
  \textbf{Supplementary information:} A step-by-step tutorial is provided on the diffEnrich
  GitHub page \url{https://github.com/SabaLab/diffEnrich}, and example data are
  included in the package.

}

%% - \Keywords{} with LaTeX markup, at least one required
%% - \Plainkeywords{} without LaTeX markup (if necessary)
%% - Should be comma-separated and in sentence case.
\Keywords{differential enrichment, KEGG REST API, \proglang{R}}
\Plainkeywords{differential enrichment, KEGG REST API, R}

%% - \Address{} of at least one author
%% - May contain multiple affiliations for each author
%%   (in extra lines, separated by \emph{and}\\).
%% - May contain multiple authors for the same affiliation
%%   (in the same first line, separated by comma).
\Address{
  Laura Saba\\
  University of Colorado\\
  Skaggs School of Pharmacy and Pharmaceutical Sciences\\
  Mail Stop C238\\
  12850 E. Montview Blvd. V20-2124\\
  Aurora, CO 80045\\
  E-mail: \email{Laura.Saba@cuanschutz.edu}
}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}


%% -- Introduction -------------------------------------------------------------

%% - In principle "as usual".
%% - But should typically have some discussion of both _software_ and _methods_.
%% - Use \proglang{}, \pkg{}, and \code{} markup throughout the manuscript.
%% - If such markup is in (sub)section titles, a plain text version has to be
%%   added as well.
%% - All software mentioned should be properly \cite-d.
%% - All abbreviations should be introduced.
%% - Unless the expansions of abbreviations are proper names (like "Journal
%%   of Statistical Software" above) they should be in sentence case (like
%%   "generalized linear models" below).

\section[Introduction]{Introduction} \label{sec:intro}

Often high throughput omics studies include a functional enrichment analysis to
glean biological insight from a list of candidate genes, proteins, metabolites,
etc. Functional enrichment examines whether the number of genes in the list
associated with a biological function or particular pathway is more than would
be expected by chance. As an example, enrichment of a particular pathway among
a list of genes that are differentially expressed after an experimental
manipulation may indicate that the pathway has been altered by that
manipulation. This analysis is rather straight forward and many solutions have
been offered (e.g., \cite{HuangDW:2009}; \cite{Kuleshov:2016}; \cite{Liao:2019};
\cite{Subramanian:2005}). A wide variety of databases have also been
used to define these pathways (e.g., \cite{KEGG:2000}) and ontologies
(e.g., \cite{Ashburner:2000}).

One key component of a statistically rigorous functional enrichment analysis is
the definition of a background data set that can be used to estimate the number
of candidate genes that are ``expected'' to be associated with the pathway by
chance, e.g., if 5\% of genes in the background data set are associated with
a pathway then 5\% of candidate gene are expected to be associated with the
pathway by chance. For many study designs, the background data set is
relatively simple to define (e.g., RNA-Seq analyses where the background data
set includes genes expressed above background).

However, for some newer omics technologies, the background data set is hard to
define. For example, LC-MS analysis can be used to identify carbonylated
proteins ( \cite{Petersen:2018}; \cite{Shearn:2019}; \cite{Shearn:2018}).
With this study design, carbonylated proteins are isolated using a BH-derivation
and then LC-MS is used to identify peptides in this isolated sample. The most
appropriate background data set would be proteins present in that tissue, but
this would require a separate analytical analysis. Furthermore, most functional
enrichment analyses involve a single gene list. However, in protein modification
studies, the typical experimental design compares the presence or absence of
particular modified proteins between multiple groups.

When there are two or more gene lists to compare and the background gene list is
not clearly defined, as is often the case in protein modification experiments,
we propose a differential enrichment analysis. In this analysis, we compare the
proportion of genes/proteins from one gene list associated with a particular
pathway to the proportion of genes/proteins from a second gene list that are
associated with that pathway. To easily execute this analysis, we have designed
an R package that uses the KEGG REST API to obtain the most recent version of
the KEGG PATHWAY (\cite{KEGG:2000}) database to initially identify
functional enrichment within a gene list using the entire KEGG transcriptome as
the background data set and then to identify differentially enriched pathways
between two gene lists. This R package includes a function to generate a
``differential enrichment'' graphic.

KEGG is a database resource for understanding high-level functions of a
biological system, such as a cell, an organism and an ecosystem, from genomic
and molecular-level information \url{https://www.kegg.jp/kegg/kegg1a.html}. KEGG is
an integrated database resource consisting of eighteen databases that are
clustered into 4 main categories: 1) systems information (e.g. hierarchies
and maps), 2) genomic information (e.g. genes and proteins), 3) chemical
information (e.g. biochemical reactions), and 4) health information (e.g. human
disease and drugs) \url{https://www.kegg.jp/kegg/kegg1a.html}.

In 2012 KEGG released its first application programming interface (API), and has
been adding features and functionality ever since. There are benefits to using
an API. First, API\textquotesingle s, like KEGG\textquotesingle s, allow users to
perform customized analyses with the most up-to-date versions of the data
contained in the database. In addition, accessing the KEGG API is very easy
using statistical programming tools like R or Python and integrating data
retrieval into user\textquotesingle s code makes the
program reproducible. To further enforce reproducibilty diffEnrich adds a date
and KEGG release tag to all data files it generates from accessing the API. For
update histories and release notes for the KEGG REST API please visit
\url{https://www.kegg.jp/kegg/rest/}.

%% -- Manuscript ---------------------------------------------------------------

%% - In principle "as usual" again.
%% - When using equations (e.g., {equation}, {eqnarray}, {align}, etc.
%%   avoid empty lines before and after the equation (which would signal a new
%%   paragraph.
%% - When describing longer chunks of code that are _not_ meant for execution
%%   (e.g., a function synopsis or list of arguments), the environment {Code}
%%   is recommended. Alternatively, a plain {verbatim} can also be used.
%%   (For executed code see the next section.)

\section{Models and software} \label{sec:models}

The basic Poisson regression model for count data is a special case of the GLM
framework \cite{McCullagh+Nelder:1989}. It describes the dependence of a count
response variable $y_i$ ($i = 1, \dots, n$) by assuming a Poisson distribution
$y_i \sim \mathrm{Pois}(\mu_i)$. The dependence of the conditional mean
$\E[y_i \, | \, x_i] = \mu_i$ on the regressors $x_i$ is then specified via a
log link and a linear predictor
%
\begin{equation} \label{eq:mean}
\log(\mu_i) \quad = \quad x_i^\top \beta,
\end{equation}
%
where the regression coefficients $\beta$ are estimated by maximum likelihood
(ML) using the iterative weighted least squares (IWLS) algorithm.

\begin{leftbar}
Note that around the \verb|{equation}| above there should be no spaces (avoided
in the {\LaTeX} code by \verb|%| lines) so that ``normal'' spacing is used and
not a new paragraph started.
\end{leftbar}

\proglang{R} provides a very flexible implementation of the general GLM
framework in the function \fct{glm} \citep{Chambers+Hastie:1992} in the
\pkg{stats} package. Its most important arguments are
\begin{Code}
glm(formula, data, subset, na.action, weights, offset,
  family = gaussian, start = NULL, control = glm.control(...),
  model = TRUE, y = TRUE, x = FALSE, ...)
\end{Code}
where \code{formula} plus \code{data} is the now standard way of specifying
regression relationships in \proglang{R}/\proglang{S} introduced in
\cite{Chambers+Hastie:1992}. The remaining arguments in the first line
(\code{subset}, \code{na.action}, \code{weights}, and \code{offset}) are also
standard  for setting up formula-based regression models in
\proglang{R}/\proglang{S}. The arguments in the second line control aspects
specific to GLMs while the arguments in the last line specify which components
are returned in the fitted model object (of class \class{glm} which inherits
from \class{lm}). For further arguments to \fct{glm} (including alternative
specifications of starting values) see \code{?glm}. For estimating a Poisson
model \code{family = poisson} has to be specified.

\begin{leftbar}
As the synopsis above is a code listing that is not meant to be executed,
one can use either the dedicated \verb|{Code}| environment or a simple
\verb|{verbatim}| environment for this. Again, spaces before and after should be
avoided.

Finally, there might be a reference to a \verb|{table}| such as
Table~\ref{tab:overview}. Usually, these are placed at the top of the page
(\verb|[t!]|), centered (\verb|\centering|), with a caption below the table,
column headers and captions in sentence style, and if possible avoiding vertical
lines.
\end{leftbar}

\begin{table}[t!]
\centering
\begin{tabular}{lllp{7.4cm}}
\hline
Type           & Distribution & Method   & Description \\ \hline
GLM            & Poisson      & ML       & Poisson regression: classical GLM,
                                           estimated by maximum likelihood (ML) \\
               &              & Quasi    & ``Quasi-Poisson regression'':
                                           same mean function, estimated by
                                           quasi-ML (QML) or equivalently
                                           generalized estimating equations (GEE),
                                           inference adjustment via estimated
                                           dispersion parameter \\
               &              & Adjusted & ``Adjusted Poisson regression'':
                                           same mean function, estimated by
                                           QML/GEE, inference adjustment via
                                           sandwich covariances\\
               & NB           & ML       & NB regression: extended GLM,
                                           estimated by ML including additional
                                           shape parameter \\ \hline
Zero-augmented & Poisson      & ML       & Zero-inflated Poisson (ZIP),
                                           hurdle Poisson \\
               & NB           & ML       & Zero-inflated NB (ZINB),
                                           hurdle NB \\ \hline
\end{tabular}
\caption{\label{tab:overview} Overview of various count regression models. The
table is usually placed at the top of the page (\texttt{[t!]}), centered
(\texttt{centering}), has a caption below the table, column headers and captions
are in sentence style, and if possible vertical lines should be avoided.}
\end{table}


%% -- Illustrations ------------------------------------------------------------

%% - Virtually all JSS manuscripts list source code along with the generated
%%   output. The style files provide dedicated environments for this.
%% - In R, the environments {Sinput} and {Soutput} - as produced by Sweave() or
%%   or knitr using the render_sweave() hook - are used (without the need to
%%   load Sweave.sty).
%% - Equivalently, {CodeInput} and {CodeOutput} can be used.
%% - The code input should use "the usual" command prompt in the respective
%%   software system.
%% - For R code, the prompt "R> " should be used with "+  " as the
%%   continuation prompt.
%% - Comments within the code chunks should be avoided - these should be made
%%   within the regular LaTeX text.

\section{Illustrations} \label{sec:illustrations}

For a simple illustration of basic Poisson and NB count regression the
\code{quine} data from the \pkg{MASS} package is used. This provides the number
of \code{Days} that children were absent from school in Australia in a
particular year, along with several covariates that can be employed as regressors.
The data can be loaded by
%
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{data}\hlstd{(}\hlstr{"quine"}\hlstd{,} \hlkwc{package} \hlstd{=} \hlstr{"MASS"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
%
and a basic frequency distribution of the response variable is displayed in
Figure~\ref{fig:quine}.

\begin{leftbar}
For code input and output, the style files provide dedicated environments.
Either the ``agnostic'' \verb|{CodeInput}| and \verb|{CodeOutput}| can be used
or, equivalently, the environments \verb|{Sinput}| and \verb|{Soutput}| as
produced by \fct{Sweave} or \pkg{knitr} when using the \code{render_sweave()}
hook. Please make sure that all code is properly spaced, e.g., using
\code{y = a + b * x} and \emph{not} \code{y=a+b*x}. Moreover, code input should
use ``the usual'' command prompt in the respective software system. For
\proglang{R} code, the prompt \code{"R> "} should be used with \code{"+  "} as
the continuation prompt. Generally, comments within the code chunks should be
avoided -- and made in the regular {\LaTeX} text instead. Finally, empty lines
before and after code input/output should be avoided (see above).
\end{leftbar}

\begin{figure}[t!]
\centering
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}
\includegraphics[width=\maxwidth]{figure/visualization-1} 

\end{knitrout}
\caption{\label{fig:quine} Frequency distribution for number of days absent
from school.}
\end{figure}

As a first model for the \code{quine} data, we fit the basic Poisson regression
model. (Note that JSS prefers when the second line of code is indented by two
spaces.)
%
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{m_pois} \hlkwb{<-} \hlkwd{glm}\hlstd{(Days} \hlopt{~} \hlstd{(Eth} \hlopt{+} \hlstd{Sex} \hlopt{+} \hlstd{Age} \hlopt{+} \hlstd{Lrn)}\hlopt{^}\hlnum{2}\hlstd{,} \hlkwc{data} \hlstd{= quine,}
  \hlkwc{family} \hlstd{= poisson)}
\end{alltt}
\end{kframe}
\end{knitrout}
%
To account for potential overdispersion we also consider a negative binomial
GLM.
%
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(}\hlstr{"MASS"}\hlstd{)}
\hlstd{m_nbin} \hlkwb{<-} \hlkwd{glm.nb}\hlstd{(Days} \hlopt{~} \hlstd{(Eth} \hlopt{+} \hlstd{Sex} \hlopt{+} \hlstd{Age} \hlopt{+} \hlstd{Lrn)}\hlopt{^}\hlnum{2}\hlstd{,} \hlkwc{data} \hlstd{= quine)}
\end{alltt}
\end{kframe}
\end{knitrout}
%
In a comparison with the BIC the latter model is clearly preferred.
%
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{BIC}\hlstd{(m_pois, m_nbin)}
\end{alltt}
\begin{verbatim}
##        df      BIC
## m_pois 18 2046.851
## m_nbin 19 1157.235
\end{verbatim}
\end{kframe}
\end{knitrout}
%
Hence, the full summary of that model is shown below.
%
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(m_nbin)}
\end{alltt}
\begin{verbatim}
## 
## Call:
## glm.nb(formula = Days ~ (Eth + Sex + Age + Lrn)^2, data = quine, 
##     init.theta = 1.60364105, link = log)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.0857  -0.8306  -0.2620   0.4282   2.0898  
## 
## Coefficients: (1 not defined because of singularities)
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  3.00155    0.33709   8.904  < 2e-16 ***
## EthN        -0.24591    0.39135  -0.628  0.52977    
## SexM        -0.77181    0.38021  -2.030  0.04236 *  
## AgeF1       -0.02546    0.41615  -0.061  0.95121    
## AgeF2       -0.54884    0.54393  -1.009  0.31296    
## AgeF3       -0.25735    0.40558  -0.635  0.52574    
## LrnSL        0.38919    0.48421   0.804  0.42153    
## EthN:SexM    0.36240    0.29430   1.231  0.21818    
## EthN:AgeF1  -0.70000    0.43646  -1.604  0.10876    
## EthN:AgeF2  -1.23283    0.42962  -2.870  0.00411 ** 
## EthN:AgeF3   0.04721    0.44883   0.105  0.91622    
## EthN:LrnSL   0.06847    0.34040   0.201  0.84059    
## SexM:AgeF1   0.02257    0.47360   0.048  0.96198    
## SexM:AgeF2   1.55330    0.51325   3.026  0.00247 ** 
## SexM:AgeF3   1.25227    0.45539   2.750  0.00596 ** 
## SexM:LrnSL   0.07187    0.40805   0.176  0.86019    
## AgeF1:LrnSL -0.43101    0.47948  -0.899  0.36870    
## AgeF2:LrnSL  0.52074    0.48567   1.072  0.28363    
## AgeF3:LrnSL       NA         NA      NA       NA    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for Negative Binomial(1.6036) family taken to be 1)
## 
##     Null deviance: 235.23  on 145  degrees of freedom
## Residual deviance: 167.53  on 128  degrees of freedom
## AIC: 1100.5
## 
## Number of Fisher Scoring iterations: 1
## 
## 
##               Theta:  1.604 
##           Std. Err.:  0.214 
## 
##  2 x log-likelihood:  -1062.546
\end{verbatim}
\end{kframe}
\end{knitrout}



%% -- Summary/conclusions/discussion -------------------------------------------

\section{Summary and discussion} \label{sec:summary}

\begin{leftbar}
As usual \dots
\end{leftbar}


%% -- Optional special unnumbered sections -------------------------------------

\section*{Computational details}

\begin{leftbar}
If necessary or useful, information about certain computational details
such as version numbers, operating systems, or compilers could be included
in an unnumbered section. Also, auxiliary packages (say, for visualizations,
maps, tables, \dots) that are not cited in the main text can be credited here.
\end{leftbar}

The results in this paper were obtained using
\proglang{R}~3.6.1 with the
\pkg{MASS}~7.3.51.4 package. \proglang{R} itself
and all packages used are available from the Comprehensive
\proglang{R} Archive Network (CRAN) at
\url{https://CRAN.R-project.org/}.


\section*{Acknowledgments}

\begin{leftbar}
All acknowledgments (note the AE spelling) should be collected in this
unnumbered section before the references. It may contain the usual information
about funding and feedback from colleagues/reviewers/etc. Furthermore,
information such as relative contributions of the authors may be added here
(if any).
\end{leftbar}


%% -- Bibliography -------------------------------------------------------------
%% - References need to be provided in a .bib BibTeX database.
%% - All references should be made with \cite, \citet, \citep, \citealp etc.
%%   (and never hard-coded). See the FAQ for details.
%% - JSS-specific markup (\proglang, \pkg, \code) should be used in the .bib.
%% - Titles in the .bib should be in title case.
%% - DOIs should be included where available.

\bibliography{refs}


%% -- Appendix (if any) --------------------------------------------------------
%% - After the bibliography with page break.
%% - With proper section titles and _not_ just "Appendix".

\newpage

\begin{appendix}

\section{More technical details} \label{app:technical}

\begin{leftbar}
Appendices can be included after the bibliography (with a page break). Each
section within the appendix should have a proper section title (rather than
just \emph{Appendix}).

For more technical style details, please check out JSS's style FAQ at
\url{https://www.jstatsoft.org/pages/view/style#frequently-asked-questions}
which includes the following topics:
\begin{itemize}
  \item Title vs.\ sentence case.
  \item Graphics formatting.
  \item Naming conventions.
  \item Turning JSS manuscripts into \proglang{R} package vignettes.
  \item Trouble shooting.
  \item Many other potentially helpful details\dots
\end{itemize}
\end{leftbar}


\section[Using BibTeX]{Using \textsc{Bib}{\TeX}} \label{app:bibtex}

\begin{leftbar}
References need to be provided in a \textsc{Bib}{\TeX} file (\code{.bib}). All
references should be made with \verb|\cite|, \verb|\citet|, \verb|\citep|,
\verb|\citealp| etc.\ (and never hard-coded). This commands yield different
formats of author-year citations and allow to include additional details (e.g.,
pages, chapters, \dots) in brackets. In case you are not familiar with these
commands see the JSS style FAQ for details.

Cleaning up \textsc{Bib}{\TeX} files is a somewhat tedious task -- especially
when acquiring the entries automatically from mixed online sources. However,
it is important that informations are complete and presented in a consistent
style to avoid confusions. JSS requires the following format.
\begin{itemize}
  \item JSS-specific markup (\verb|\proglang|, \verb|\pkg|, \verb|\code|) should
    be used in the references.
  \item Titles should be in title case.
  \item Journal titles should not be abbreviated and in title case.
  \item DOIs should be included where available.
  \item Software should be properly cited as well. For \proglang{R} packages
    \code{citation("pkgname")} typically provides a good starting point.
\end{itemize}
\end{leftbar}

\end{appendix}

%% -----------------------------------------------------------------------------


\end{document}
